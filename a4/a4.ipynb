{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c4ae75b3-ee1e-4dc1-9cb8-70cf40341a60",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Assignment 4 - Spam classification using Naïve Bayes\n",
    "\n",
    "Contributer, time spent:\n",
    "\n",
    "- William Albertsson, 0 hours \n",
    "- Carl Holmberg, 0 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "29725fc9-97e4-49aa-acf3-892dc7e5717d",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## 1. Preprocessing\n",
    "### a) \n",
    "*Note that the email files contain a lot of extra information, besides the actual message. Ignore that for now and run on the entire text. Further down (in the higher grade part), you will be asked to filter out the headers and footers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "3b86b105-9c0f-4a55-aaf6-b956c3174675",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     611,
     611
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5877,
    "execution_start": 1644503229236,
    "source_hash": "9a52bd6c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "def get_directory_contents(directory):\n",
    "    contents = []\n",
    "    for path in pathlib.Path(directory).iterdir():\n",
    "        f = open(path, \"r\", errors=\"ignore\")\n",
    "        contents.append(f.read())\n",
    "    return contents\n",
    "\n",
    "\n",
    "hard_ham_mails = get_directory_contents(\"./data/2002/hard-ham\")\n",
    "easy_ham_mails = get_directory_contents(\n",
    "    \"./data/2002/easy-ham\"\n",
    ") #+ get_directory_contents(\"./data/2003/easy-ham-2\")\n",
    "spam_mails = get_directory_contents(\"./data/2002/spam\") + get_directory_contents(\n",
    "    \"./data/2003/spam-2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "53409cba-ee91-4179-8383-14b3447fd71a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## b)\n",
    "*We don’t want to train and test on the same data. Split the spam and the ham datasets \n",
    "in a training set and a test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "48dd6f72-5b6c-4d31-85b1-7745212229cd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1644503235128,
    "source_hash": "9f657d9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(l, p):\n",
    "    random.shuffle(l)\n",
    "    size = int(len(l) * p)\n",
    "    fst = l[size:]\n",
    "    snd = l[:size]\n",
    "    return (fst, snd)\n",
    "\n",
    "test_set_size = 0.8\n",
    "\n",
    "hard_ham_train, hard_ham_test = train_test_split(hard_ham_mails, test_set_size)\n",
    "easy_ham_train, easy_ham_test = train_test_split(easy_ham_mails, test_set_size)\n",
    "spam_train,     spam_test     = train_test_split(spam_mails, test_set_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a90359b9-b296-4a7b-be4f-fc22d9a95c78",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## 2. Python program\n",
    "\n",
    "*Using a Naïve Bayes classifier (e.g. Sklearn), classifies the test sets and reports the \n",
    "percentage of ham and spam test sets that were classified correctly. You can use \n",
    "CountVectorizer to transform the email texts into vectors. Please note that there are \n",
    "different types of Naïve Bayes Classifier in SKlearn (Document is available here). Test two \n",
    "of these classifiers: 1. Multinomial Naive Bayes and 2. Bernoulli Naive Bayes that are well \n",
    "suited for this problem. For the case of Bernoulli Naive Bayes you should use the \n",
    "parameter binarize to make the features binary.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "4b8ac53e-e351-4c6d-8422-9c5e7e849211",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1938,
    "execution_start": 1644503306045,
    "source_hash": "c1937b59",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "# Inputs are lists of strings\n",
    "def NB_classifier(hamtrain, spamtrain, hamtest, spamtest, model):\n",
    "    # Create dataframes (train/test)\n",
    "    train_data = zip((hamtrain+spamtrain), ['ham']*len(hamtrain)+['spam']*len(spamtrain))\n",
    "    df_train = pd.DataFrame(train_data, columns=[\"msg\", \"label\"])\n",
    "    \n",
    "    test_data = zip((hamtest+spamtest), ['ham']*len(hamtest)+['spam']*len(spamtest))\n",
    "    df_test = pd.DataFrame(test_data, columns=[\"msg\", \"label\"])\n",
    "    # Vectorization\n",
    "    vec_count = CountVectorizer()\n",
    "    dtm_train = vec_count.fit_transform(df_train['msg']).toarray()\n",
    "    dtm_test  = vec_count.transform(df_test['msg']).toarray()\n",
    "    labels_train = df_train['label']\n",
    "    labels_test  = df_test['label']\n",
    "\n",
    "    # Train model\n",
    "    model.fit(dtm_train, labels_train)\n",
    "    # Predictions\n",
    "    preds = model.predict(dtm_test)\n",
    "    acc = metrics.accuracy_score(labels_test, preds);\n",
    "    print('  Model Accuracy: {} ≈ {}%'.format(acc,int(acc*100)))\n",
    "    \n",
    "\n",
    "\n",
    "def program(ham_train, ham_test, spam_train, spamtest):\n",
    "    #gaussianNB_classifier(['hello darkness my old friend', 'ive had a dream', 'pipes are cool', 'darkness darkness'], \n",
    "    # ['bitcoin now', 'bless you jesus christ', 'cute cats in your area'], [], ['friend darkness darkness darknass'])\n",
    "    print('Bernoulli Naive Bayes:')\n",
    "    NB_classifier(ham_train, spam_train, ham_test, spam_test, model = BernoulliNB(binarize=True))\n",
    "    print('Multinomial Naive Bayes:')\n",
    "    NB_classifier(ham_train, spam_train, ham_test, spam_test, model = MultinomialNB())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss the differences between these two(Bernoulli Naive Bayes, Multinomial Naive Bayes) classifiers.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "*Run your program on:*\n",
    "\n",
    "  i. *Spam versus easy-ham*\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "  Model Accuracy: 0.8347850519808935 ≈ 83%\n",
      "Multinomial Naive Bayes:\n",
      "  Model Accuracy: 0.952233773531891 ≈ 95%\n"
     ]
    }
   ],
   "source": [
    "# SPAM VS EASY-HAM\n",
    "program(easy_ham_train, easy_ham_test, spam_train, spam_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ii. *Spam versus hard-ham*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "  Model Accuracy: 0.8976148923792903 ≈ 89%\n",
      "Multinomial Naive Bayes:\n",
      "  Model Accuracy: 0.9598603839441536 ≈ 95%\n"
     ]
    }
   ],
   "source": [
    "#SPAM VS HARD-HAM\n",
    "program(hard_ham_train, hard_ham_test, spam_train, spam_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "*To avoid classification based on common and uninformative words it is common to filter these out.*\n",
    "\n",
    "* *Argue why this may be useful. Try finding the words that are too common/uncommon in the dataset.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove some data by filtering out common words that probably exists in both the spam and ham sets.\n",
    "This would not neccessarly have a large effect on the accuracy but it could help speed up the process of training and testing the model.\n",
    "When the data is common, they probably exist in both of the groups and can therefore not be used to distinguish the sets.\n",
    "Removing uncommon words could actually effect the accuracy of the program.\n",
    "It could help remove data points that are to few to actually indicate a trend and help classify the emails better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Use the parameters in Sklearn’s CountVectorizer to filter out these words. Run the updated program on your data and record how the results differ from 3. You have two options to do this in Sklearn: either using the words found in part (a) or letting Sklearn do it for you.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=dffe86c5-8c56-427e-b159-7e1448518018' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9357978c-74ba-42e7-b947-6e2081e2e6d5",
  "interpreter": {
   "hash": "da40960069ffc8d0b62d50f0809fa1f6da87c56681680216ca42630a646728c8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
