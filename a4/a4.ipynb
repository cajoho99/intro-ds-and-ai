{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Assignment 4 - Spam classification using Naïve Bayes\n\nContributer, time spent:\n\n- William Albertsson,  hours \n- Carl Holmberg, 0 hours",
   "metadata": {
    "cell_id": "c4ae75b3-ee1e-4dc1-9cb8-70cf40341a60",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Preprocessing\n### a) \n*Note that the email files contain a lot of extra information, besides the actual message. Ignore that for now and run on the entire text. Further down (in the higher grade part), you will be asked to filter out the headers and footers.*",
   "metadata": {
    "cell_id": "29725fc9-97e4-49aa-acf3-892dc7e5717d",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "3b86b105-9c0f-4a55-aaf6-b956c3174675",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9a52bd6c",
    "execution_start": 1644503229236,
    "execution_millis": 5877,
    "deepnote_output_heights": [
     611,
     611
    ],
    "deepnote_cell_type": "code"
   },
   "source": "import pathlib\n\ndef get_directory_contents(directory):\n    contents = []\n    for path in pathlib.Path(directory).iterdir():\n        f = open(path, \"r\", errors=\"ignore\")\n        contents.append(f.read())\n    return contents\n\n\nhard_ham_mails = get_directory_contents(\"./data/2002/hard-ham\")\neasy_ham_mails = get_directory_contents(\n    \"./data/2002/easy-ham\"\n) + get_directory_contents(\"./data/2003/easy-ham-2\")\nspam_mails = get_directory_contents(\"./data/2002/spam\") + get_directory_contents(\n    \"./data/2003/spam-2\"\n)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## b)\n*We don’t want to train and test on the same data. Split the spam and the ham datasets \nin a training set and a test set.*",
   "metadata": {
    "cell_id": "53409cba-ee91-4179-8383-14b3447fd71a",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "48dd6f72-5b6c-4d31-85b1-7745212229cd",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9f657d9",
    "execution_start": 1644503235128,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "import random\n\ndef train_test_split(l, p):\n    random.shuffle(l)\n    size = int(len(l) * p)\n    fst = l[size:]\n    snd = l[:size]\n    return (fst, snd)\n\ntest_set_size = 0.8\n\nham_train, ham_test   = train_test_split((hard_ham_mails + easy_ham_mails),test_set_size)\nspam_train, spam_test = train_test_split(spam_mails,                        test_set_size)\n\n\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Python program\n\n*Using a Naïve Bayes classifier (e.g. Sklearn), classifies the test sets and reports the \npercentage of ham and spam test sets that were classified correctly. You can use \nCountVectorizer to transform the email texts into vectors. Please note that there are \ndifferent types of Naïve Bayes Classifier in SKlearn (Document is available here). Test two \nof these classifiers: 1. Multinomial Naive Bayes and 2. Bernoulli Naive Bayes that are well \nsuited for this problem. For the case of Bernoulli Naive Bayes you should use the \nparameter binarize to make the features binary. Discuss the differences between these \ntwo classifiers.*",
   "metadata": {
    "cell_id": "a90359b9-b296-4a7b-be4f-fc22d9a95c78",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "4b8ac53e-e351-4c6d-8422-9c5e7e849211",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c1937b59",
    "execution_start": 1644503306045,
    "execution_millis": 1938,
    "deepnote_cell_type": "code"
   },
   "source": "import pandas as pd\nfrom sklearn import metrics\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import GaussianNB\n\n# Inputs are lists of strings\ndef gaussianNB_classifier(hamtrain, spamtrain, hamtest, spamtest):\n    # Create dataframes (train/test)\n    print('Data frames:')\n    train_data = zip((hamtrain+spamtrain), ['ham']*len(hamtrain)+['spam']*len(spamtrain))\n    df_train = pd.DataFrame(train_data, columns=[\"msg\", \"label\"])\n    \n    test_data = zip((hamtest+spamtest), ['ham']*len(hamtest)+['spam']*len(spamtest))\n    df_test = pd.DataFrame(test_data, columns=[\"msg\", \"label\"])\n    # Vectorization\n    print('Vectorizatinos:')\n    vec_count = CountVectorizer()\n    dtm_train = vec_count.fit_transform(df_train['msg']).toarray()\n    dtm_test  = vec_count.transform(df_test['msg']).toarray()\n    labels_train = df_train['label']\n    labels_test  = df_test['label']\n\n    # Train model\n    print('Model time:')\n    print(dtm_train)\n    print(labels_train)\n    model = GaussianNB()\n    model.fit(dtm_train, labels_train)\n    # Predictions\n    preds = model.predict(dtm_test)\n    acc = metrics.accuracy_score(labels_test, preds);\n    print('Model Accuracy: {} ≈ {}%'.format(acc,int(acc*100)))\n    \n\n\n#gaussianNB_classifier(['hello darkness my old friend', 'ive had a dream', 'pipes are cool', 'darkness darkness'], ['bitcoin now', 'bless you jesus christ', 'cute cats in your area'], [], ['friend darkness darkness darknass'])\ngaussianNB_classifier(ham_train, spam_train, ham_test, spam_test)\n    ",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Data frames:\nVectorizatinos:\nModel time:\n[[2 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 2 ... 0 0 0]\n ...\n [0 1 0 ... 0 0 0]\n [0 4 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n0        ham\n1        ham\n2        ham\n3        ham\n4        ham\n        ... \n1216    spam\n1217    spam\n1218    spam\n1219    spam\n1220    spam\nName: label, Length: 1221, dtype: object\n",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "KernelInterrupted",
     "evalue": "Execution interrupted by the Jupyter kernel.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=dffe86c5-8c56-427e-b159-7e1448518018' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "9357978c-74ba-42e7-b947-6e2081e2e6d5",
  "deepnote_execution_queue": []
 }
}